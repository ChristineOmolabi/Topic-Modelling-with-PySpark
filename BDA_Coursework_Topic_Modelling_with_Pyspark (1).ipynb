{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu8Msbh1u4-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c057c9-b289-4e95-c834-7925a5eb3785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285388 sha256=795fc63bec75c68100e924c4fee0405419e8fc332dae758f244b5bcf2b57c451\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "#Installing Pyspark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#begin session\n",
        "from pyspark.sql import SparkSession, SQLContext\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "T2AmbGrEvPUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc=spark.sparkContext\n",
        "sqlContext = SQLContext(sc)"
      ],
      "metadata": {
        "id": "jPUEXfliD7P-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47af4882-0dbc-492f-8803-d217eec39bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Wkz2ivcGvil_",
        "outputId": "066bf263-f2da-42d6-e6b3-dd7e987f448a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x788d912f53f0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://50595b5836e3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Topic Modelling2').getOrCreate()"
      ],
      "metadata": {
        "id": "yQD5-KunyW6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import dataset\n",
        "data = spark.read.csv('tokyo_2020_tweets.csv', header = True, inferSchema = True)\n",
        "data.show()"
      ],
      "metadata": {
        "id": "_Pz7iOXFyKvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4512efd-fcf6-4b7d-c600-3ac24effd952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------------------+--------------------+-------------------+--------------+------------+---------------+-------------+-------------------+--------------------+--------------------+-------------------+--------+---------+----------+\n",
            "|                  id|           user_name|      user_location|    user_description|       user_created|user_followers|user_friends|user_favourites|user_verified|               date|                text|            hashtags|             source|retweets|favorites|is_retweet|\n",
            "+--------------------+--------------------+-------------------+--------------------+-------------------+--------------+------------+---------------+-------------+-------------------+--------------------+--------------------+-------------------+--------+---------+----------+\n",
            "| 1418888645105356803|  Abhishek Srivastav|       Udupi, India|Trying to be medi...|2021-02-01 06:33:51|            45|          39|            293|        False|2021-07-24 10:59:49| Let the party begin|                null|               null|    null|     null|      null|\n",
            "|         #Tokyo2020\"|       ['Tokyo2020']|Twitter for Android|                 0.0|                0.0|         False|        null|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "| 1418888377680678918|Saikhom Mirabai C...|     Manipur, India|Indian weightlift...|2018-04-07 10:10:22|          5235|           5|           2969|        False|2021-07-24 10:58:45|Congratulations #...|       ['Tokyo2020']|Twitter for Android|     0.0|      0.0|     False|\n",
            "| 1418888260886073345|        Big Breaking|             Global|All breaking news...|2021-05-29 08:51:25|          3646|           3|              5|        False|2021-07-24 10:58:17|   Big Breaking Now |                null|               null|    null|     null|      null|\n",
            "|Tokyo Olympic Upd...|                null|               null|                null|               null|          null|        null|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "|Japan won his fir...| C‚Ä¶ https://t.co/...|               null| Twitter for Android|                0.0|           1.0|       False|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "| 1418888172864299008|International Hoc...|           Lausanne|Official Internat...|2010-10-20 10:45:59|        103975|        2724|          36554|         True|2021-07-24 10:57:56|     Q4: üá¨üáß3-1üáøüá¶|                null|               null|    null|     null|      null|\n",
            "|Great Britain fin...| with Jack Waller...|               null|     Twitter Web App|                1.0|           0.0|       False|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "| 1418886894478270464|        Cameron Hart|          Australia|Football & Tennis...|2020-10-31 08:46:17|             6|          37|             31|        False|2021-07-24 10:52:51|All I can think o...|['Tokyo2020', 'Ar...| Twitter for iPhone|     0.0|      0.0|     False|\n",
            "| 1418885092571766792|          Sab Joke H|              India|         Follows you|2020-09-05 19:50:35|           107|          88|            102|        False|2021-07-24 10:45:42|#Tokyo2020 #Olympics|                null|               null|    null|     null|      null|\n",
            "|       #MirabaiChanu|                null|               null|                null|               null|          null|        null|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "|      #Weightlifting|                null|               null|                null|               null|          null|        null|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "|   Women Empowerment|                null|               null|                null|               null|          null|        null|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "|REAL             ...|['Tokyo2020', 'Ol...|Twitter for Android|                 0.0|                0.0|         False|        null|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "| 1418880445161353228|             evija87|  City by the water|Eva. | Watch Luci...|2009-12-01 23:55:34|           224|         652|          84310|        False|2021-07-24 10:27:14|Can't help but ch...|                null|               null|    null|     null|      null|\n",
            "|Zambia goal diffe...|                null|               null|                null|               null|          null|        null|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "|Well done on gett...|                null|    Twitter Web App|                 0.0|                0.0|         False|        null|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "| 1418889399203475466|     INQUIRER Sports|             Manila|The official Twit...|2009-11-11 08:20:00|         48937|         522|            555|         True|2021-07-24 11:02:49|@inquirerdotnet @...|                null|          TweetDeck|     0.0|      0.0|     False|\n",
            "| 1418889399081656321|International Hoc...|           Lausanne|Official Internat...|2010-10-20 10:45:59|        103976|        2724|          36554|         True|2021-07-24 11:02:49|    Q3 üá®üá¶ 1-4 üá©üá™|                null|               null|    null|     null|      null|\n",
            "|Green card for Ca...|                null|               null|                null|               null|          null|        null|           null|         null|               null|                null|                null|               null|    null|     null|      null|\n",
            "+--------------------+--------------------+-------------------+--------------------+-------------------+--------------+------------+---------------+-------------+-------------------+--------------------+--------------------+-------------------+--------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#View columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "Fo6wvLDp5BVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194aa2de-70d9-4c27-b075-51e327b0e0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id',\n",
              " 'user_name',\n",
              " 'user_location',\n",
              " 'user_description',\n",
              " 'user_created',\n",
              " 'user_followers',\n",
              " 'user_friends',\n",
              " 'user_favourites',\n",
              " 'user_verified',\n",
              " 'date',\n",
              " 'text',\n",
              " 'hashtags',\n",
              " 'source',\n",
              " 'retweets',\n",
              " 'favorites',\n",
              " 'is_retweet']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a corpus from the text column\n",
        "dt = data.select('text')\n",
        "dt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfwaJPyl5Mhp",
        "outputId": "1a39c3da-950a-4b43-bc80-5379d9b38baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "| Let the party begin|\n",
            "|                null|\n",
            "|Congratulations #...|\n",
            "|   Big Breaking Now |\n",
            "|                null|\n",
            "|                null|\n",
            "|     Q4: üá¨üáß3-1üáøüá¶|\n",
            "|                null|\n",
            "|All I can think o...|\n",
            "|#Tokyo2020 #Olympics|\n",
            "|                null|\n",
            "|                null|\n",
            "|                null|\n",
            "|                null|\n",
            "|Can't help but ch...|\n",
            "|                null|\n",
            "|                null|\n",
            "|@inquirerdotnet @...|\n",
            "|    Q3 üá®üá¶ 1-4 üá©üá™|\n",
            "|                null|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check total null values\n",
        "dt.toPandas()['text'].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz0y-UlE5Y-0",
        "outputId": "8f8da5de-c8fc-4e48-dc76-7397fc5df9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199272"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop null values\n",
        "dt = dt.dropna()\n",
        "dt.show()"
      ],
      "metadata": {
        "id": "qzbn1ttF5-q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d292ad7-b9ed-4545-c809-8454813be650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "| Let the party begin|\n",
            "|Congratulations #...|\n",
            "|   Big Breaking Now |\n",
            "|     Q4: üá¨üáß3-1üáøüá¶|\n",
            "|All I can think o...|\n",
            "|#Tokyo2020 #Olympics|\n",
            "|Can't help but ch...|\n",
            "|@inquirerdotnet @...|\n",
            "|    Q3 üá®üá¶ 1-4 üá©üá™|\n",
            "|Hearty Congratula...|\n",
            "|                 0.0|\n",
            "|Gymnastics ‚ù§Ô∏è #To...|\n",
            "|Morning everyone!...|\n",
            "| #Tokyo2020 #Tennis |\n",
            "|Up next for Carlo...|\n",
            "|Congrates @miraba...|\n",
            "|The wait for a we...|\n",
            "|#Tokyo2020   #Mir...|\n",
            "|#Tokyo2020 #Olymp...|\n",
            "|Well done to #Tea...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check again\n",
        "dt.toPandas()['text'].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL0PFn5TB1fi",
        "outputId": "b890a6a7-0f82-49ea-932e-d5bc1b1c7bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning the corpus\n",
        "from pyspark.sql.functions import udf, col, lower, regexp_replace\n",
        "# Clean text\n",
        "dt_clean = dt.select((lower(regexp_replace('text', \"[^a-zA-Z\\\\s]\", \"\")).alias('cleaned_text')))\n",
        "dt_clean.show()"
      ],
      "metadata": {
        "id": "taxAG1Y4tIQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f1191b-3427-4d15-d8b1-e8d8198014bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|        cleaned_text|\n",
            "+--------------------+\n",
            "| let the party begin|\n",
            "|congratulations t...|\n",
            "|   big breaking now |\n",
            "|                  q |\n",
            "|all i can think o...|\n",
            "|      tokyo olympics|\n",
            "|cant help but che...|\n",
            "|inquirerdotnet ft...|\n",
            "|                q   |\n",
            "|hearty congratula...|\n",
            "|                    |\n",
            "|   gymnastics  tokyo|\n",
            "|morning everyone ...|\n",
            "|       tokyo tennis |\n",
            "|up next for carlo...|\n",
            "|congrates mirabai...|\n",
            "|the wait for a we...|\n",
            "|tokyo   mirabaich...|\n",
            "|tokyo olympics a ...|\n",
            "|well done to team...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import proprocessing and model libraries\n",
        "import pyspark.ml.feature\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.clustering import LDA"
      ],
      "metadata": {
        "id": "iJolU_LS8KKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializer\n",
        "tokenizer = Tokenizer(inputCol='cleaned_text', outputCol='tokened')\n",
        "SW = StopWordsRemover(inputCol='tokened', outputCol='sw_removed')\n",
        "CV = CountVectorizer(inputCol='sw_removed', outputCol='vectors',minDF= 10, maxDF = 97)\n",
        "lda = LDA(featuresCol= 'vectors', maxIter=10, k=5)"
      ],
      "metadata": {
        "id": "2ykzFIaa8jmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize corpus\n",
        "token= tokenizer.transform(dt_clean.select('cleaned_text'))\n",
        "token.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb-b4lOwvFuR",
        "outputId": "a5adf003-0265-4908-d9d7-7a253e30ef75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|        cleaned_text|             tokened|\n",
            "+--------------------+--------------------+\n",
            "| let the party begin|[let, the, party,...|\n",
            "|congratulations t...|[congratulations,...|\n",
            "|   big breaking now |[big, breaking, now]|\n",
            "|                  q |                 [q]|\n",
            "|all i can think o...|[all, i, can, thi...|\n",
            "|      tokyo olympics|   [tokyo, olympics]|\n",
            "|cant help but che...|[cant, help, but,...|\n",
            "|inquirerdotnet ft...|[inquirerdotnet, ...|\n",
            "|                q   |                 [q]|\n",
            "|hearty congratula...|[hearty, congratu...|\n",
            "|                    |                  []|\n",
            "|   gymnastics  tokyo|[gymnastics, , to...|\n",
            "|morning everyone ...|[morning, everyon...|\n",
            "|       tokyo tennis |     [tokyo, tennis]|\n",
            "|up next for carlo...|[up, next, for, c...|\n",
            "|congrates mirabai...|[congrates, mirab...|\n",
            "|the wait for a we...|[the, wait, for, ...|\n",
            "|tokyo   mirabaich...|[tokyo, , , mirab...|\n",
            "|tokyo olympics a ...|[tokyo, olympics,...|\n",
            "|well done to team...|[well, done, to, ...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove stopwords\n",
        "filt_words = SW.transform(token)\n",
        "filt_words.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqP34cxavrHY",
        "outputId": "5581eaa0-00bd-465c-f2fd-11fea3705d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|        cleaned_text|             tokened|          sw_removed|\n",
            "+--------------------+--------------------+--------------------+\n",
            "| let the party begin|[let, the, party,...| [let, party, begin]|\n",
            "|congratulations t...|[congratulations,...|[congratulations,...|\n",
            "|   big breaking now |[big, breaking, now]|     [big, breaking]|\n",
            "|                  q |                 [q]|                 [q]|\n",
            "|all i can think o...|[all, i, can, thi...|[think, every, ti...|\n",
            "|      tokyo olympics|   [tokyo, olympics]|   [tokyo, olympics]|\n",
            "|cant help but che...|[cant, help, but,...|[cant, help, chee...|\n",
            "|inquirerdotnet ft...|[inquirerdotnet, ...|[inquirerdotnet, ...|\n",
            "|                q   |                 [q]|                 [q]|\n",
            "|hearty congratula...|[hearty, congratu...|[hearty, congratu...|\n",
            "|                    |                  []|                  []|\n",
            "|   gymnastics  tokyo|[gymnastics, , to...|[gymnastics, , to...|\n",
            "|morning everyone ...|[morning, everyon...|[morning, everyon...|\n",
            "|       tokyo tennis |     [tokyo, tennis]|     [tokyo, tennis]|\n",
            "|up next for carlo...|[up, next, for, c...|[next, carlos, yu...|\n",
            "|congrates mirabai...|[congrates, mirab...|[congrates, mirab...|\n",
            "|the wait for a we...|[the, wait, for, ...|[wait, weightlift...|\n",
            "|tokyo   mirabaich...|[tokyo, , , mirab...|[tokyo, , , mirab...|\n",
            "|tokyo olympics a ...|[tokyo, olympics,...|[tokyo, olympics,...|\n",
            "|well done to team...|[well, done, to, ...|[well, done, team...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorize the model using countvectorizer\n",
        "cv_model = CV.fit(filt_words)\n",
        "CVM = cv_model.transform(filt_words)\n",
        "CVM.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzbyUKa7wBeQ",
        "outputId": "0d810a93-eee4-44a5-c52a-a195de7a3b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|        cleaned_text|             tokened|          sw_removed|             vectors|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "| let the party begin|[let, the, party,...| [let, party, begin]|   (6260,[11],[1.0])|\n",
            "|congratulations t...|[congratulations,...|[congratulations,...|        (6260,[],[])|\n",
            "|   big breaking now |[big, breaking, now]|     [big, breaking]|        (6260,[],[])|\n",
            "|                  q |                 [q]|                 [q]|        (6260,[],[])|\n",
            "|all i can think o...|[all, i, can, thi...|[think, every, ti...|        (6260,[],[])|\n",
            "|      tokyo olympics|   [tokyo, olympics]|   [tokyo, olympics]|        (6260,[],[])|\n",
            "|cant help but che...|[cant, help, but,...|[cant, help, chee...|        (6260,[],[])|\n",
            "|inquirerdotnet ft...|[inquirerdotnet, ...|[inquirerdotnet, ...|(6260,[97,185,513...|\n",
            "|                q   |                 [q]|                 [q]|        (6260,[],[])|\n",
            "|hearty congratula...|[hearty, congratu...|[hearty, congratu...|        (6260,[],[])|\n",
            "|                    |                  []|                  []|        (6260,[],[])|\n",
            "|   gymnastics  tokyo|[gymnastics, , to...|[gymnastics, , to...|        (6260,[],[])|\n",
            "|morning everyone ...|[morning, everyon...|[morning, everyon...|        (6260,[],[])|\n",
            "|       tokyo tennis |     [tokyo, tennis]|     [tokyo, tennis]|        (6260,[],[])|\n",
            "|up next for carlo...|[up, next, for, c...|[next, carlos, yu...| (6260,[4187],[1.0])|\n",
            "|congrates mirabai...|[congrates, mirab...|[congrates, mirab...|        (6260,[],[])|\n",
            "|the wait for a we...|[the, wait, for, ...|[wait, weightlift...|        (6260,[],[])|\n",
            "|tokyo   mirabaich...|[tokyo, , , mirab...|[tokyo, , , mirab...|        (6260,[],[])|\n",
            "|tokyo olympics a ...|[tokyo, olympics,...|[tokyo, olympics,...|(6260,[1670,2849]...|\n",
            "|well done to team...|[well, done, to, ...|[well, done, team...|        (6260,[],[])|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the processed corpus into the lda modle for training\n",
        "lda_mod = lda.fit(CVM)\n",
        "lda_mod"
      ],
      "metadata": {
        "id": "oUu0BAc7w6qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e5cd38-edb9-477b-af3b-5667594a8e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LocalLDAModel: uid=LDA_38bc8af52d23, k=5, numFeatures=6260"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize variables to extract the trained topic index\n",
        "ext_vocab = cv_model.vocabulary\n",
        "ext_topics = lda_mod.describeTopics()\n",
        "ext_topics.rdd.map(lambda row: row['termIndices']).collect()"
      ],
      "metadata": {
        "id": "lPRhu2m_yBYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c43a4e-157a-4b2d-d8fa-0d928821ee16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[81, 3, 96, 0, 82, 202, 357, 349, 325, 252],\n",
              " [258, 42, 128, 186, 106, 129, 120, 216, 68, 75],\n",
              " [16, 78, 116, 41, 23, 180, 152, 166, 114, 136],\n",
              " [7, 24, 190, 400, 239, 178, 69, 140, 124, 111],\n",
              " [4, 100, 18, 15, 217, 54, 151, 540, 211, 308]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#code to link and retrieve the the topics as words in a list\n",
        "Mod_topics = ext_topics.rdd.map(lambda row: row['termIndices']).map(lambda idx_list: [ext_vocab[idx] for idx in idx_list]).collect()"
      ],
      "metadata": {
        "id": "Q3npPz7ByPBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#view topics\n",
        "Mod_topics[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVlXMiy3yaij",
        "outputId": "ab66be7d-d990-47c0-a654-4b2556d71c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['strikes',\n",
              " 'leave',\n",
              " 'sweet',\n",
              " 'congratulation',\n",
              " 'serbia',\n",
              " 'pro',\n",
              " 'austria',\n",
              " 'spoonflower',\n",
              " 'control',\n",
              " 'divers']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DA77vKwbdfrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#view all topics\n",
        "from os import truncate\n",
        "from pyspark.sql.types import StringType\n",
        "LDA_Topics = spark.createDataFrame(Mod_topics, StringType()).show(truncate = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45ig6tNays5m",
        "outputId": "180d54a3-022b-490a-e911-4cd8ee34a51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------+\n",
            "|                                                                                                        value|\n",
            "+-------------------------------------------------------------------------------------------------------------+\n",
            "|[tkdbradly, funnearnapp, juegosolimpicos, blozadainq, killing, goldmedal, kim, daniil, beyond, ianuragthakur]|\n",
            "|                                         [sir, bar, simply, chan, indeed, ying, rush, sister, nadine, nearly]|\n",
            "|             [drop, congratulates, bhavanidevi, indiaattokyo, sign, carapaz, divyansh, rather, greece, tight]|\n",
            "|                               [rain, cheung, catching, heads, defense, million, sitting, blow, lucky, wants]|\n",
            "|                  [strikes, leave, sweet, congratulation, serbia, pro, austria, spoonflower, control, divers]|\n",
            "+-------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}